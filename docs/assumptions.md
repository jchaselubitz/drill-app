# Project Assumptions & Local Setup

## Assumptions
- **Authentication**: Supabase email magic link auth will be used, but auth UI is not yet implemented in the mobile app scaffold.
- **AI Provider**: OpenAI GPT or Google PaLM will power content generation and scoring. The edge functions currently return mocked responses; you will wire up API calls later.
- **Lesson Length**: Each lesson starts with 10 items. Additional content will be generated by re-calling the `generate-lesson` function with the user library included.
- **Scoring Model**: Both spelling and grammar scores range from 0â€“100. The UI expects integer scores.
- **Libraries**: Terms and concepts share the same weighting model (`focusLevel`). Adjust this if you need separate behaviours.

## Prerequisites
- Node.js 18+
- Yarn or npm (Yarn is recommended for Expo projects)
- Expo CLI (`npm install -g expo-cli`)
- Supabase CLI (optional, for function emulation)

## Getting Started

1. **Install dependencies**
   ```bash
   yarn install
   ```

2. **Configure environment variables**
   - Copy `.env.example` to `.env`.
   - Fill in your Supabase project URL and anon key.
   - Provide the base URL where Supabase functions are exposed locally (for example the Supabase CLI edge runtime) via `EXPO_PUBLIC_OPENAI_PROXY_URL`.

3. **Run the Expo app**
   ```bash
   yarn start
   ```
   - Press `i` to launch the iOS simulator or `a` for Android.

4. **Emulate Supabase functions (optional)**
   ```bash
   supabase start
   supabase functions serve --env-file ../.env.local
   ```
   - Deploy your edge functions with `supabase functions deploy generate-lesson` etc.

5. **Type checking & linting**
   ```bash
   yarn typecheck
   yarn lint
   ```

## Next Steps
- Replace the mocked edge-function helpers in `supabase/functions/_shared/openai.ts` with real provider calls.
- Connect the mobile client to Supabase auth and realtime features as needed.
- Persist lesson progress and libraries by integrating the schema described in `docs/mock-database.md`.
